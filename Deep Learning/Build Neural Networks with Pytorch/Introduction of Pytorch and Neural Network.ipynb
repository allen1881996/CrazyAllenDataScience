{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of Pytorch and Neural Network\n",
    "## By Allen Huang "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络3blue1brown: https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.marekrei.com/blog/wp-content/uploads/2014/02/neuralnetwork2.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://www.marekrei.com/blog/wp-content/uploads/2014/02/neuralnetwork2.png\",width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks consist of a bunch of \"neurons\" which are values that start off as your input data, and then get multiplied by weights, summed together, and then passed through an activation function to produce new values, and this process then repeats over however many \"layers\" your neural network has to then produce an output.\n",
    "\n",
    "The input(x1,x2,x3) data must be numerical. We call the input features, which could also be some sort of categorical type of feature. We need to convert the features(like color, length, how many legs) into numerical data. Pixel value is very commen. \n",
    "\n",
    "These input pass to hidden layers. We do not have control over these layers. In your hidden layers (\"hidden\" just generally refers to the fact that the programmer doesn't really set or control the values to these layers, the machine does), these are neurons, numbering in however many you want (you control how many there are, just not the value of those neurons), and then they lead to an output layer. \n",
    "\n",
    "The output is usually either a single neuron for regression tasks, or as many neurons as you have classes. In the above case, there are 2 output neurons, so maybe this neural network is classifying dogs vs cats. Each neuron's value can be thought of as a confidence score for if the neural network thinks it's that class. We just find out which one is the greatest, and that's the prediction of our neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whichever neuron has the highest value, that's the predicted class! So maybe the top of the two output neurons is \"dog\" and then \"cat\" on the bottom. If the dog value is the largest one, then that would be the prediction of the neural network.\n",
    "\n",
    "Connecting all of the neurons are those lines. Each of them is a weight, and possibly a bias. So the inputs get multiplied by the weights, the biases are added in, then it gets summed at the next neuron, passed through an activation function, to be the next input value for the next one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pythonprogramming.net/static/images/machine-learning/artificial-neuron-model-sigmoid-activiation-function.png\" width=\"700\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What goes on in a single neural?\n",
    "Image(url= \"https://pythonprogramming.net/static/images/machine-learning/artificial-neuron-model-sigmoid-activiation-function.png\",width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example of this \"zoomed in\" so to speak to show the mechanism for just a single neuron. You can see the inputs from other neurons come in, they're multiplied by the weights, bias are optionally added, then they are summed together. After this summation, they pass through an activation function. The activation function's job is to calculate whether or not, or how much, a neuron is \"firing.\" A neuron could output a 0 or 1 to be off or on, but also, more commonly, could instead output a range between 0 and 1, for example, which serves as input to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: scaling down, to be between 0 and 1\n",
    "\n",
    "- Weight and biases: parameter, machine have ability to modify every single one of these parameters independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pytorch library, like the other deep learning libraries, really is just a library that does operations on tensors.\n",
    "\n",
    "What's a tensor?!\n",
    "\n",
    "You can just think of a tensor like an array. Really all we're doing is basically multiplying arrays here. That's all there is to it. The fancy bits are when we run an optimization algorithm on all those weights to start modifying them. Neural networks themselves are actually super basic and simple. Their optimization is a little more challenging, but most of these deep learning libraries also help you a bit with that math. If you want to learn how to do everything yourself by hand, stay tuned later in the series. I just don't think it would be wise to lead with that.\n",
    "\n",
    "__*download Pytorch using: conda install pytorch torchvision -c pytorch*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "# Pytorch is numpy on the GPU, tensor is an array\n",
    "import torch\n",
    "\n",
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, it's just [5 2, 3 1]. Simple stuff!\n",
    "\n",
    "Because it's a lot of operations on arrays, Pytorch aims to mimic the very popular numeric library in Python called NumPy. Many of the exact same methods exist, usually with the same names, but sometimes different ones. One common task is to make an \"empty\" array, of some shape. In NumPy, we use np.zeros. In Pytorch, we do the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "# specify shape\n",
    "x = torch.zeros([2,5])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9468, 0.5984, 0.8497, 0.9162, 0.9963],\n",
      "        [0.1323, 0.1449, 0.2750, 0.7287, 0.1380]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9468, 0.5984, 0.8497, 0.9162, 0.9963, 0.1323, 0.1449, 0.2750, 0.7287,\n",
       "         0.1380]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape \n",
    "y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9468, 0.5984, 0.8497, 0.9162, 0.9963],\n",
       "        [0.1323, 0.1449, 0.2750, 0.7287, 0.1380]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9468, 0.5984, 0.8497, 0.9162, 0.9963, 0.1323, 0.1449, 0.2750, 0.7287,\n",
      "         0.1380]])\n"
     ]
    }
   ],
   "source": [
    "# re-assign is needed \n",
    "y = y.view([1,10])\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
