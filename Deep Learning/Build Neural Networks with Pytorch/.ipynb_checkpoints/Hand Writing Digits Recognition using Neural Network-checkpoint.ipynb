{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Writing Digits Recognition using Neural Network\n",
    "## By Allen Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /anaconda3/lib/python3.7/site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.16.4)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: torch in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.3.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /anaconda3/lib/python3.7/site-packages (from torchvision) (6.1.0)\n"
     ]
    }
   ],
   "source": [
    "# use data from Pytorch's \"torchvision\" \n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first thing we have to consider is our data. In most tutorials, this bit is often overlooked in the interest of going straight to the training of a neural network. That said, as a programmer working with neural networks, one of your largest tasks is preprocessing your data and formatting it in such as way to be easiest for the neural network to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now though, we're just trying to learn about how to do a basic neural network in pytorch, so we'll use torchvision here, to load the MNIST dataset, which is a image-based dataset showing handwritten digits from 0-9, and your job is to write a neural network to classify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data is out-of-sample data that your machine have never seen.\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "# specify where you want the data to go, '' means locally\n",
    "# things we want to apply to the data, the data is not natively already in tensor, so we need to convert it to tensor\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "# then, the data in downloaded in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it to another type of object that help us iterate over that data\n",
    "# specify the batch size   \n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Batch_size__\n",
    "\n",
    "How many data at a time do we want to pass to our model. It also can help us to generalize. Commen batch size is from 8-64. \n",
    "\n",
    "__Training and Testing data split__\n",
    "\n",
    "To train any machine learning model, we want to first off have training and validation datasets. This is so we can use data that the machine has never seen before to \"test\" the machine.\n",
    "\n",
    "__Shuffling__\n",
    "\n",
    "Then, within our training dataset, we generally want to randomly shuffle the input data as much as possible to hopefully not have any patterns in the data that might throw the machine off.\n",
    "\n",
    "For example, if you fed the machine a bunch of images of zeros, the machine would learn to classify everything as zero. Then you'd start feeding it ones, and the machine would figure out pretty quick to classify everything as ones...and so on. Whenever you stop, the machine would probably just classify everything as the last thing you trained on. If you shuffle the data, your machine is much more likely to figure out what's what.\n",
    "\n",
    "__Scaling and normalization__\n",
    "\n",
    "Another consideration at some point in the pipeline is usually scaling/normalization of the dataset. In general, we want all input data to be between zero and one. Often many datasets will contain data in ranges that are not within this range, and we generally will want to come up with a way to scale the data to be within this range.\n",
    "\n",
    "For example, an image is comprised of pixel values, most often in the range of 0 to 255. To scale image data, you usually just divide by 255. That's it. Even though all features are just pixels, and all you do is divide by 255 before passing to the neural network, this makes a huge difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 2, 2, 2, 9, 3, 9, 9, 9, 8])]\n"
     ]
    }
   ],
   "source": [
    "# there is ten example of handwriten numbers, and ten tensors of the actual output\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration will contain a batch of 10 elements (that was the batch size we chose), and 10 classes. Let's just look at one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[0][0], data[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is our input data. The features. The thing we want to predict. y is our label. The classification. The thing we hope the neural network can learn to predict. We can see this by doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6431, 1.0000, 0.7765,\n",
      "          0.2627, 0.2627, 0.2627, 0.6980, 0.3647, 0.1647, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8157, 0.1922, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.8392, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8549, 0.6588,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.6980, 0.8510, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8863,\n",
      "          0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.7804, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.1804, 0.1804, 0.1804,\n",
      "          0.1804, 0.7294, 0.4275, 0.9608, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.6118, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.3333, 0.7255, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5137, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7216, 0.4824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.8118, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9647, 0.8510, 0.3294, 0.0863, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5373, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8510, 0.3725, 0.0941,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5412, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6863, 0.0941,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0863, 0.1059, 0.1059, 0.1059, 0.3804, 0.8431, 0.9765,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8667, 0.1882,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216,\n",
      "          0.5843, 0.5843, 0.9647, 0.9922, 0.9922, 0.9922, 0.7059, 0.1059,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4000, 0.0980, 0.0000, 0.0000, 0.1020,\n",
      "          0.6667, 0.6667, 0.9686, 0.9922, 0.9922, 0.9922, 0.9922, 0.2549,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0706, 0.9255, 0.9647, 0.9333, 0.9255, 0.9255, 0.9333,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.5412, 0.0196,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2510, 0.4863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8902, 0.2824, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1647, 0.8627, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7686, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.8118, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9490, 0.7686, 0.2471, 0.0235, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4196, 0.6706, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.7922, 0.5098, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0863, 0.6902, 0.9922, 0.9922, 0.5216, 0.2549,\n",
      "          0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize \n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is data balancing?__\n",
    "\n",
    "Recall before how I explained that if we don't shuffle our data, the machine will learn things like what the last few hundred classes were in a row, and probably just predict that from there on out.\n",
    "\n",
    "Well, with data balancing, a similar thing could occur.\n",
    "\n",
    "Imagine you have a dataset of cats and dogs. 7200 images are dogs, and 1800 are cats. This is quite the imbalance. The classifier is highly likely to find out that it can very quickly and easily get to a 72% accuracy by simple always predicting dog. It is highly unlikely that the model will recover from something like this.\n",
    "\n",
    "Other times, the imbalance isn't quite as severe, but still enough to make the model almost always predict a certain way except in the most obvious-to-it-of cases. Anyway, it's best if we can balance the dataset.\n",
    "\n",
    "By \"balance,\" I mean make sure there are the same number of examples for each classifications in training.\n",
    "\n",
    "Sometimes, this simply isn't possible. There are ways for us to handle for this with special class weighting for the optimizer to take note of, but, even this doesn't always work. Personally, I've never had success with this in any real world application.\n",
    "\n",
    "In our case, how might we confirm the balance of data? Well, we just need to iterate over everything and make a count. Pretty simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871667%\n",
      "1: 11.236667%\n",
      "2: 9.930000%\n",
      "3: 10.218333%\n",
      "4: 9.736667%\n",
      "5: 9.035000%\n",
      "6: 9.863333%\n",
      "7: 10.441667%\n",
      "8: 9.751667%\n",
      "9: 9.915000%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    # data have two set of tensors\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0:5f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn is like a object, and F is like a function \n",
    "# in nn you need to initialize things, and in F you just need to pass in parameters\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch.nn import gives us access to some helpful neural network things, such as various neural network layer types (things like regular fully-connected layers, convolutional layers (for imagery), recurrent layers...etc). For now, we've only spoken about fully-connected layers, so we will just be using those for now.\n",
    "\n",
    "The torch.nn.functional area specifically gives us access to some handy functions that we might not want to write ourselves. We will be using the relu or \"rectified linear\" activation function for our neurons. Instead of writing all of the code for these things, we can just import them, since these are things everyone will be needing in their deep learning code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our model, we're going to create a class. We'll call this class net and this net will inhereit from the nn.Module class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "# this Net class in inherient from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # running the initialization for nn.Module as well as \n",
    "        # we are going to define the fully connected layers to the neural network \n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        # fc stand for fully connected , fc1 is our first fully connected layer\n",
    "        # nn.Linear(input, output), input (what coming into this layer) is our image, but we can not pass in image, we need to pass flattened image\n",
    "        # our target is two make a three layers of sixty-four neurons for our hidden layers\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        # fc4 is our output layer, we have 10 classes (0-9)\n",
    "        # we have three output of 64, so it's a three layers 64 neurons \n",
    "        \n",
    "    def forward(self, x):\n",
    "    # for our data to pass through (feed forward, one direction), x is our data \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # x = self.fc1(x) is the way we pass in our data\n",
    "        # F.relu is our activation function (whether or not the neuron is firing like the human brain, avoid number explosions), which stand for rectified linear \n",
    "        # activation function runs on each layer's output data, instead of output data\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        # apply a log_softmax to x, because we want the output is like a probability distribution\n",
    "        # dimension = 1 is similar to 2 axis, we are going to pass batches of data\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inherient__\n",
    "\n",
    "Typically, when you inherit from a parent class, that init method doesn't actually get run. This is how we can run that init method of the parent class, which can sometimes be required...because we actually want to initialize things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Defining fully connected layers__\n",
    "\n",
    "All we're doing is just defining values for some layers, we're calling them fc1, fc2...etc, but you could call them whatever you wanted. The fc just stands for fully connected. Fully connected refers to the point that every neuron in this layer is going to be fully connected to attaching neurons. Nothing fancy going on here! Recall, each \"connection\" comes with weights and possibly biases, so each connection is a \"parameter\" for the neural network to play with.\n",
    "\n",
    "In our case, we have 4 layers. Each of our nn.Linear layers expects the first parameter to be the input size, and the 2nd parameter is the output size.\n",
    "\n",
    "So, our first layer takes in 28x28, because our images are 28x28 images of hand-drawn digits. A basic neural network is going to expect to have a flattened array, so not a 28x28, but instead a 1x784.\n",
    "\n",
    "Then this outputs 64 connections. This means the next layer, fc2 takes in 64 (the next layer is always going to accept however many connections the previous layer outputs). From here, this layer ouputs 64, then fc3 just does the same thing.\n",
    "\n",
    "fc4 takes in 64, but outputs 10. Why 10? Our \"output\" layer needs 10 neurons. Why 10 neurons? We have 10 classes.\n",
    "\n",
    "__Pass in data__\n",
    "\n",
    "Notice the x is a parameter for the forward method. This will be our input data. As you can see, we literally just \"pass\" this data through the layers. This could in theory learn with some problems, but this is going to most likely cause some serious explosions in values. The neural network could control this, but probably wont. Instead, what we're missing is an activation function for the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Activation Function__\n",
    "\n",
    "We use activation functions to take the sum of the input data * weights, and then to determine if the neuron is firing or not. Initially, these were often step functions that were literally either 0 or 1, but then we found that sigmoids and other types of functions were better.\n",
    "\n",
    "Currently, the most popular is the rectified linear, or relu, activation function. Basically, these activation functions are keeping our data scaled between 0 and 1.\n",
    "\n",
    "__Softmax__\n",
    "\n",
    "Finally, for the output layer, we're going to use softmax. Softmax makes sense to use for a multi-class problem, where each thing can only be one class or the other. This means the outputs themselves are a confidence score, adding up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in some data into our neural network\n",
    "X = torch.rand(28,28)\n",
    "X = X.view(-1, 28*28)\n",
    "# 1 specify this input will be of an unknown shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3586, -2.4049, -2.2353, -2.2430, -2.2579, -2.3337, -2.3623, -2.2566,\n",
       "         -2.3204, -2.2690]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__About -1__\n",
    "\n",
    "You should understand the 28*28 part, but why the leading -1?\n",
    "\n",
    "Any input and output to our neural network is expected to be a group feature sets.\n",
    "\n",
    "Even if you intend to just pass 1 set of features, you still have to pass it as a \"list\" of features.\n",
    "\n",
    "In our case, we really just want a 1x784, and we could say that, but you will more often is -1 used in these shapings. Why? -1 suggests \"any size\". So it could be 1, 12, 92, 15295...etc. It's a handy way for that bit to be variable. In this case, the variable part is how many \"samples\" we'll pass through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__\n",
    "\n",
    "It should be a tensor that contains a tensor of our 10 possible classes. Why was it a tensor in a tensor? Because input and output needs to be variable. Even if we just want to predict on one input, it needs to be a list of inputs and the output will be a list of outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss__\n",
    "\n",
    "How wrong is the model. Our loss_function is what calculates \"how far off\" our classifications are from reality. As humans, we tend to think of things in terms of either right, or wrong. With a neural network, and arguably humans too, our accuracy is actually some sort of scaling score.\n",
    "\n",
    "For example, you might be highly confident that something is the case, but you are wrong. Compare this to a time when you really aren't certain either way, but maybe think something, but are wrong. In these cases, the degree to which you're wrong doesn't matter in terms of the choice necessarily, but in terms of you learning, it does.\n",
    "\n",
    "In terms of a machine learning by tweaking lots of little parameters to slowly get closer and closer to fitting, it definitely matters how wrong things are.\n",
    "\n",
    "For this, we use loss, which is a measurement of how far off the neural network is from the targeted output. There are a few types of loss calculations. A popular one is mean squared error, but we're trying to use these scalar-valued classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# the first argument is to everything that a adjustable in our model, what is adjustable by the optimizer\n",
    "# lr is learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pythonprogramming.net/static/images/machine-learning/learning-rate-too-high-too-low.png\" width=\"800\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://pythonprogramming.net/static/images/machine-learning/learning-rate-too-high-too-low.png\",width=800, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pythonprogramming.net/static/images/machine-learning/learning-rate-just-right.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://pythonprogramming.net/static/images/machine-learning/learning-rate-just-right.png\",width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pythonprogramming.net/static/images/machine-learning/decaying-lr.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://pythonprogramming.net/static/images/machine-learning/decaying-lr.png\",width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate over our data. In general, you will make more than just 1 pass through your entire training dataset.\n",
    "\n",
    "Each full pass through your dataset is referred to as an epoch. In general, you will probably have somewhere between 3 and 10 epochs, but there's no hard rule here.\n",
    "\n",
    "Too few epochs, and your model wont learn everything it could have.\n",
    "\n",
    "Too many epochs and your model will over fit to your in-sample data (basically memorize the in-sample data, and perform poorly on out of sample data).\n",
    "\n",
    "Let's go with 3 epochs for now. So we will loop over epochs, and each epoch will loop over our data. Something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of features and labels\n",
    "        X, y = data  # unpack the data. X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__net.zero_grad()__\n",
    "\n",
    "Every line here is commented, but the concept of gradients might not be clear. Once we pass data through our neural network, getting an output, we can compare that output to the desired output. With this, we can compute the gradients for each parameter, which our optimizer (Adam, SGD...etc) uses as information for updating weights.\n",
    "\n",
    "This is why it's important to do a net.zero_grad() for every step, otherwise these gradients will add up for every pass, and then we'll be re-optimizing for previous gradients that we already optimized for. There could be times when you intend to have the gradients sum per pass, like maybe you have a batch of 10, but you want to optimize per 50 or something. I don't think people really do that, but the idea of Pytorch is to let you do whatever you want.\n",
    "\n",
    "__F.nll_loss()__\n",
    "\n",
    "nll loss is for our output is not a vector, it's a singular value or a scalar value. If your data is a one hot vector like [0,1,0,0,0], you need to use mean squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.976\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # we do not want gradients to be caculated in these out of sample data\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[2].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[2].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) tensor(9)\n",
      "tensor(8) tensor(3)\n",
      "tensor(8) tensor(9)\n",
      "tensor(3) tensor(7)\n",
      "tensor(6) tensor(4)\n",
      "tensor(8) tensor(4)\n",
      "tensor(7) tensor(2)\n",
      "tensor(0) tensor(6)\n",
      "tensor(9) tensor(4)\n",
      "tensor(8) tensor(6)\n",
      "tensor(2) tensor(8)\n",
      "tensor(2) tensor(8)\n",
      "tensor(6) tensor(4)\n",
      "tensor(8) tensor(1)\n",
      "tensor(3) tensor(2)\n",
      "tensor(4) tensor(8)\n",
      "tensor(8) tensor(5)\n",
      "tensor(9) tensor(7)\n",
      "tensor(8) tensor(9)\n",
      "tensor(9) tensor(7)\n",
      "tensor(5) tensor(3)\n",
      "tensor(4) tensor(5)\n",
      "tensor(2) tensor(1)\n",
      "tensor(0) tensor(6)\n",
      "tensor(3) tensor(5)\n",
      "tensor(5) tensor(6)\n",
      "tensor(2) tensor(7)\n",
      "tensor(6) tensor(4)\n",
      "tensor(0) tensor(4)\n",
      "tensor(8) tensor(6)\n",
      "tensor(9) tensor(7)\n",
      "tensor(2) tensor(7)\n",
      "tensor(3) tensor(9)\n",
      "tensor(4) tensor(9)\n",
      "tensor(9) tensor(4)\n",
      "tensor(5) tensor(9)\n",
      "tensor(9) tensor(4)\n",
      "tensor(9) tensor(5)\n",
      "tensor(3) tensor(8)\n",
      "tensor(9) tensor(7)\n",
      "tensor(6) tensor(5)\n",
      "tensor(3) tensor(5)\n",
      "tensor(2) tensor(8)\n",
      "tensor(9) tensor(7)\n",
      "tensor(9) tensor(7)\n",
      "tensor(5) tensor(1)\n",
      "tensor(7) tensor(8)\n",
      "tensor(6) tensor(4)\n",
      "tensor(3) tensor(5)\n",
      "tensor(7) tensor(3)\n",
      "tensor(0) tensor(8)\n",
      "tensor(8) tensor(5)\n",
      "tensor(3) tensor(7)\n",
      "tensor(8) tensor(2)\n",
      "tensor(3) tensor(8)\n",
      "tensor(3) tensor(8)\n",
      "tensor(4) tensor(9)\n",
      "tensor(8) tensor(7)\n",
      "tensor(3) tensor(8)\n",
      "tensor(8) tensor(1)\n",
      "tensor(9) tensor(7)\n",
      "tensor(3) tensor(5)\n",
      "tensor(9) tensor(4)\n",
      "tensor(3) tensor(7)\n",
      "tensor(0) tensor(2)\n",
      "tensor(8) tensor(3)\n",
      "tensor(0) tensor(6)\n",
      "tensor(9) tensor(4)\n",
      "tensor(2) tensor(1)\n",
      "tensor(8) tensor(5)\n",
      "tensor(6) tensor(5)\n",
      "tensor(0) tensor(8)\n",
      "tensor(3) tensor(5)\n",
      "tensor(0) tensor(9)\n",
      "tensor(3) tensor(7)\n",
      "tensor(8) tensor(5)\n",
      "tensor(9) tensor(5)\n",
      "tensor(1) tensor(9)\n",
      "tensor(9) tensor(3)\n",
      "tensor(0) tensor(2)\n",
      "tensor(9) tensor(4)\n",
      "tensor(3) tensor(5)\n",
      "tensor(3) tensor(5)\n",
      "tensor(7) tensor(2)\n",
      "tensor(5) tensor(9)\n",
      "tensor(1) tensor(6)\n",
      "tensor(4) tensor(7)\n",
      "tensor(8) tensor(5)\n",
      "tensor(9) tensor(4)\n",
      "tensor(9) tensor(4)\n",
      "tensor(0) tensor(8)\n",
      "tensor(3) tensor(7)\n",
      "tensor(7) tensor(3)\n",
      "tensor(7) tensor(9)\n",
      "tensor(8) tensor(1)\n",
      "tensor(5) tensor(3)\n",
      "tensor(5) tensor(3)\n",
      "tensor(9) tensor(4)\n",
      "tensor(2) tensor(1)\n",
      "tensor(9) tensor(5)\n",
      "tensor(9) tensor(7)\n",
      "tensor(0) tensor(6)\n",
      "tensor(2) tensor(8)\n",
      "tensor(3) tensor(7)\n",
      "tensor(9) tensor(7)\n",
      "tensor(9) tensor(4)\n",
      "tensor(0) tensor(6)\n",
      "tensor(8) tensor(7)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(9)\n",
      "tensor(4) tensor(6)\n",
      "tensor(8) tensor(4)\n",
      "tensor(2) tensor(3)\n",
      "tensor(0) tensor(5)\n",
      "tensor(8) tensor(5)\n",
      "tensor(5) tensor(8)\n",
      "tensor(3) tensor(9)\n",
      "tensor(0) tensor(8)\n",
      "tensor(8) tensor(2)\n",
      "tensor(9) tensor(4)\n",
      "tensor(9) tensor(4)\n",
      "tensor(2) tensor(7)\n",
      "tensor(9) tensor(5)\n",
      "tensor(8) tensor(5)\n",
      "tensor(6) tensor(4)\n",
      "tensor(8) tensor(7)\n",
      "tensor(3) tensor(2)\n",
      "tensor(0) tensor(6)\n",
      "tensor(3) tensor(1)\n",
      "tensor(6) tensor(4)\n",
      "tensor(1) tensor(7)\n",
      "tensor(8) tensor(9)\n",
      "tensor(2) tensor(0)\n",
      "tensor(0) tensor(8)\n",
      "tensor(0) tensor(9)\n",
      "tensor(7) tensor(2)\n",
      "tensor(3) tensor(1)\n",
      "tensor(7) tensor(9)\n",
      "tensor(8) tensor(2)\n",
      "tensor(0) tensor(3)\n",
      "tensor(7) tensor(4)\n",
      "tensor(5) tensor(9)\n",
      "tensor(7) tensor(2)\n",
      "tensor(7) tensor(3)\n",
      "tensor(3) tensor(9)\n",
      "tensor(4) tensor(9)\n",
      "tensor(7) tensor(8)\n",
      "tensor(0) tensor(5)\n",
      "tensor(9) tensor(4)\n",
      "tensor(8) tensor(6)\n",
      "tensor(2) tensor(7)\n",
      "tensor(3) tensor(2)\n",
      "tensor(3) tensor(8)\n",
      "tensor(5) tensor(3)\n",
      "tensor(4) tensor(9)\n",
      "tensor(0) tensor(8)\n",
      "tensor(4) tensor(6)\n",
      "tensor(6) tensor(9)\n",
      "tensor(9) tensor(4)\n",
      "tensor(8) tensor(0)\n",
      "tensor(6) tensor(1)\n",
      "tensor(8) tensor(1)\n",
      "tensor(3) tensor(2)\n",
      "tensor(8) tensor(1)\n",
      "tensor(2) tensor(7)\n",
      "tensor(2) tensor(4)\n",
      "tensor(7) tensor(3)\n",
      "tensor(7) tensor(4)\n",
      "tensor(0) tensor(7)\n",
      "tensor(0) tensor(4)\n",
      "tensor(9) tensor(4)\n",
      "tensor(3) tensor(5)\n",
      "tensor(8) tensor(3)\n",
      "tensor(3) tensor(5)\n",
      "tensor(8) tensor(3)\n",
      "tensor(3) tensor(5)\n",
      "tensor(0) tensor(3)\n",
      "tensor(8) tensor(7)\n",
      "tensor(9) tensor(3)\n",
      "tensor(3) tensor(9)\n",
      "tensor(5) tensor(9)\n",
      "tensor(0) tensor(9)\n",
      "tensor(9) tensor(8)\n",
      "tensor(2) tensor(6)\n",
      "tensor(9) tensor(0)\n",
      "tensor(9) tensor(1)\n",
      "tensor(5) tensor(9)\n",
      "tensor(5) tensor(0)\n",
      "tensor(9) tensor(7)\n",
      "tensor(7) tensor(1)\n",
      "tensor(9) tensor(8)\n",
      "tensor(6) tensor(1)\n",
      "tensor(4) tensor(6)\n",
      "tensor(9) tensor(4)\n",
      "tensor(8) tensor(5)\n",
      "tensor(3) tensor(2)\n",
      "tensor(8) tensor(1)\n",
      "tensor(8) tensor(1)\n",
      "tensor(8) tensor(1)\n",
      "tensor(8) tensor(1)\n",
      "tensor(8) tensor(1)\n",
      "tensor(6) tensor(8)\n",
      "tensor(8) tensor(1)\n",
      "tensor(9) tensor(4)\n",
      "tensor(8) tensor(5)\n",
      "tensor(8) tensor(2)\n",
      "tensor(6) tensor(4)\n",
      "tensor(9) tensor(4)\n",
      "tensor(2) tensor(7)\n",
      "tensor(6) tensor(0)\n",
      "tensor(5) tensor(9)\n",
      "tensor(3) tensor(5)\n",
      "tensor(3) tensor(7)\n",
      "tensor(6) tensor(8)\n",
      "tensor(9) tensor(4)\n",
      "tensor(2) tensor(7)\n",
      "tensor(2) tensor(7)\n",
      "tensor(2) tensor(7)\n",
      "tensor(5) tensor(8)\n",
      "tensor(9) tensor(7)\n",
      "tensor(4) tensor(9)\n",
      "tensor(8) tensor(0)\n",
      "tensor(7) tensor(1)\n",
      "tensor(7) tensor(2)\n",
      "tensor(7) tensor(4)\n",
      "tensor(0) tensor(6)\n",
      "tensor(1) tensor(2)\n",
      "tensor(6) tensor(5)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(2)\n",
      "tensor(0) tensor(5)\n",
      "tensor(0) tensor(5)\n",
      "tensor(0) tensor(2)\n",
      "tensor(9) tensor(4)\n",
      "tensor(0) tensor(6)\n",
      "tensor(0) tensor(2)\n",
      "tensor(9) tensor(4)\n",
      "tensor(8) tensor(3)\n",
      "tensor(6) tensor(5)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # we do not want gradients to be caculated in these out of sample data\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) != y[idx]:\n",
    "                print(torch.argmax(i), y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
